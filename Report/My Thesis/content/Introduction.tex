\chapter{Introduction} \label{ch:intro}
There is steep progress in the research and development of autonomous vehicles. The race to the top of the automobile industry, featuring companies like BMW (Bavarian Motor Works), Tesla, Waymo/Google, requires fast development and vigorous testing of novel technologies. One of the many challenges of this field is to ensure collision avoidance. With no human behind the wheel for Level 5 \cite{SAE2014} cars, the vehicle must keep track of roads and surrounding traffic participants (like vehicles and pedestrians) in different circumstances, including rain and fog, to ensure the safety of its passengers. Current collision avoidance systems based on sensors, radar, and camera would be overwhelmed with high computation demands for this purpose. Tolerating error in such a system can cause accidents, including fatality \footnote{https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe}.


The collision avoidance system in a car consists of two parts: sensing and tracking and motion planning. The sensing and tracking part is achieved by applying sophisticated algorithms on signals from sensors like radar, camera, and GPS (Global Positioning System). With decline in cost of cameras and advancement in technologies in image processing, image analysis, and object detection, sensing and tracking is developing fast. Although cameras can classify vehicles, they cannot guarantee measurement in a low-light environment (e.g. night) \cite{Hirz2018}. In contrast, radar guarantees robustness to weather in exchange of a higher cost. Similarly, there are limitations in GPS, e.g. the inability to function in the urban canyon environment. Thus, one uses sensor fusion to compensate for shortcomings of specific sensors . After detecting all relevant elements in the environment, a motion planner has to find a collision-free path. Computation of such a path requires certain parameters to predict the tracked vehicle's trajectory. The sensors cannot solely measure all these parameters, hence researchers have turned to state estimation algorithms.

One of the widely-applied state estimation techniques is the Kalman filter, which can estimate target dynamics for measurement with additive Gaussian noise. Despite its simplicity, the filter is not suitable for vehicle tracking for two reasons. Firstly, statistical noise with known covariance is, unfortunately, not practical. Secondly, the filter provides point estimation, relying on which can be safety-critical. These motivate to use set-based state estimation methods.

The set-based state estimation technique computes a set of state enclosing the true state of the system as long as the dynamics are accurately modeled and the noise and perturbations have known bounds. The main steps are prediction step and correction step. The prediction step extrapolates prior estimate, while the correction step improves the extrapolation. There are multiple algorithms with varying approach for the correction step. Another differentiating factor is the choice of geometric set to represent the estimated domain. Zonotope is one of the popular choice, compared to ellipsoid and pollytopes, due to higher accuracy for a lower computation cost. Furthermore, zonotopes have gained fame for state estimation because of wrapping effect(i.e. not increasing in size due to accumulated noises over time) and Minkowski sum(i.e. the sum of zonotopes is also a zonotope).Therefore, we chose zonotopes to represent state for all the algorithms in this paper.

Set-based algorithms can be further classified into segment intersection and interval observer. The former methods focus on intersecting the set of estimated state with the set of predicted state from the measurements. These methods try to minimize the bounds of the estimated state by using different properties, like volume and radius, of the geometric set. The interval observer methods, on the other hand, design observer to minimize the error on each time step. The following sections dig deeper into each of the aforementioned methods.


The prequisite step before applying state estimation algorithms is to define the tracked vehicle in a linear model. Although there are complex models that can be used to represent a vehicle state \cite{Althoff}, not all can be used due to the unavailability of parameters like wheelbase, velocity, etc. as it is unlikely to be acquired in run-time from a tracked vehicle. Hence, the models used in this paper to compare are the simplest, yet complete enough to determine the properties of the tracked vehicle for trajectory prediction: Constant Velocity, Constant Acceleration, and the Point-Mass Model.

A high degree of accuracy and guarantee is the necessity of the collision avoidance system, hence we chose to compare the set based state estimation algorithms for different scenarios involving dynamic traffic participants from a dataset collected from intersections using drones and fixed cameras. \cite{Rath} has encouraged many sections in this paper and compares a superset of algorithms covered here; however, the algorithms were compared on simulated data, in contrast to this paper.

The paper is organized as follows. Chapter 2 presents the vehicle localization problem to be solved by state estimation algorithms. The following chapter 3 discusses the zonotope-based state estimation algorithms to be compared. Chapter 4 gives the evaluation of the algorithms, with extended results in chapter 6. Finally, chapter 5 concludes with a summary and a discussion of possible future works.




