\chapter{Introduction} \label{ch:intro}
There is steep progress in the research and development of autonomous vehicles. The race to the top of the automobile industry, featuring companies like BMW (Bavarian Motor Works), Tesla, Waymo/Google, requires fast development and vigorous testing of novel technologies. One of the many challenges of this field is to ensure collision avoidance. With no human behind the wheel for Level 5 \cite{SAE2014} cars, the vehicle must keep track of roads and surrounding traffic participants (like vehicles and pedestrians) in different circumstances, including rain and fog, to ensure the safety of its passengers. Current collision avoidance systems based on sensors, radar, and camera would be overwhelmed with high computation demands for this purpose. Tolerating error in such a system can cause accidents, including fatality \footnote{https://www.theguardian.com/technology/2018/mar/19/uber-self-driving-car-kills-woman-arizona-tempe}.


The collision avoidance system in a car consists of two parts: sensing and tracking and motion planning. The sensing and tracking part is achieved by applying sophisticated algorithms on signals from sensors like radar, camera, and GPS (Global Positioning System). With a decline in the cost for cameras and advancement in technologies in image processing, image analysis, and object detection, sensing and tracking is developing fast. Although cameras can classify vehicles, they cannot guarantee measurement in a low-light environment (e.g. night) \cite{Hirz2018}. In contrast, radar guarantees robustness to weather in exchange for a higher cost. Similarly, there are limitations in GPS, e.g. the inability to function in the urban canyon environment. Thus, one uses sensor fusion to compensate for the shortcomings of specific sensors. After detecting all relevant elements in the environment, a motion planner has to find a collision-free path. The computation of such a path requires certain parameters to predict the tracked vehicle's trajectory. The sensors cannot solely measure all these parameters, hence researchers have turned to state estimation algorithms.

One of the widely-applied state estimation techniques is the Kalman filter \cite{Kalman}, which can estimate target dynamics for measurement with additive Gaussian noise. Despite its simplicity, the filter is not suitable for vehicle localization for two reasons. Firstly, statistical noise with known covariance is, unfortunately, not practical. Secondly, the filter provides close point-estimation, relying on which can be safety-critical. These motivate to use set-based state estimation methods.

The set-based state estimation technique computes a set of state enclosing the true state of the system as long as the dynamics are accurately modeled and the noise and perturbations have known bounds. The main steps are the prediction step and the correction step. The prediction step extrapolates prior estimate, while the correction step improves the extrapolation. Algorithms vary in the approach for the correction step. Another differentiating factor is the choice of geometric shape to represent the estimated set. Zonotope is one of the popular choices, compared to ellipsoid and polytopes, due to higher accuracy to computation cost ratio. Furthermore, zonotopes have gained fame for state estimation because of wrapping effect control (i.e. reducing the increase in size by accumulating noise) and conservative Minkowski sum (i.e. the Minkowski sum of zonotopes is also a zonotope). Therefore, we chose zonotopes to represent the state for all the algorithms in this paper. The following section briefly discusses the related work on zonotopic set-based state estimation.


\section{Related Work}
In 2001, Puig et al \cite{Puig2001} used a gain matrix to map input measurement to a zonotopic set of estimation. Following in 2003, Combastel \cite{Combastel2003} used a singular value decomposition to overapproximate the estimate consistent with the input. Although the aforementioned methods are computationally light, they did not focus on the size of the estimated region. In 2005, T. Alamo et al. \cite{Alamo2005} formulated a convex optimization problem to minimize zonotope size criteria. They focused on two main size criteria: F-radius and volume. F-radius results in fast but conservative estimates, whereas volume computation is heavy, but gives tight bounds. In 2011, T. Alamo et al. \cite{Le2012} optimized P-radius to obtain good accuracy for a reasonable computation load. Initially, the algorithms were developed for single-output linear discrete systems and were later generalized to multi-output and non-linear systems.  

Another classification of set-based estimation is the interval observers, where the idea is to design observers such that the error in the estimation is minimal. Despite its high efficiency, the construction of such an observer is not very easy. Hence, the observer design requirements are relaxed in  \cite{Mazenc2011}, \cite{Raissi2012}. The relaxation results in conservatism, which led to an interval observer based on H-$\infty$ with reachability analysis \cite{Tang2019}.

\section{Paper Outline}
The algorithms evaluated in this paper are the segment intersection methods (minimizing the F-radius, P-radius, and volume) and one interval observer (based on H-$\infty$). The prerequisite step before applying state estimation algorithms is to model the tracked vehicle with a well-defined mathematical model. Although there are complex models that can be used to represent a vehicle state \cite{Althoff}, not all can be used due to the unavailability of parameters like wheelbase, velocity, etc. accessible to the ego vehicle. Hence, the models used in this paper to compare are the simplest, yet complete enough to determine the properties of the tracked vehicle for trajectory prediction: Constant Velocity, Constant Acceleration, and the Point-Mass Model.

A high degree of accuracy and guarantee is the necessity of the collision avoidance system, hence we chose to compare the set based state estimation algorithms for different scenarios involving dynamic traffic participants from a dataset collected from intersections using drones and fixed cameras. \cite{Rath} has encouraged many sections in this paper and compares a superset of algorithms covered here; however, the algorithms were compared on simulated data, in contrast to this paper.

The paper is organized as follows. Chapter 2 builds up the vehicle localization problem to be solved by state estimation algorithms. The following chapter 3 discusses the zonotope-based state estimation algorithms to be compared. In chapter 4, we evaluated the algorithms and discussed the results. Finally, chapter 5 concludes with a summary and a discussion of possible future works.




